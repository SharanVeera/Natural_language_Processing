{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b_sPihXtDgn"
      },
      "outputs": [],
      "source": [
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = '''The Gemini API gives you access to Gemini models created by Google DeepMind. Gemini models are built from the ground up to be multimodal, so you can reason seamlessly across text, images, code, and audio.'''"
      ],
      "metadata": {
        "id": "2QG3klggtL6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)\n"
      ],
      "metadata": {
        "id": "q1xr8gP-tWuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenization\n",
        "## Sentence-->paragraphs\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(corpus)\n",
        "print(sentences)\n"
      ],
      "metadata": {
        "id": "9RlUIrY_ta45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(sentences)"
      ],
      "metadata": {
        "id": "AK1Nk3dPus7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        " print (sentence)"
      ],
      "metadata": {
        "id": "CpxiION1vFGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(corpus)\n",
        "print(words)"
      ],
      "metadata": {
        "id": "mi8mnFgnvXn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YYRfgmrrvlBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "  print(word_tokenize(sentence))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uqnFWzCSvsPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "Words = wordpunct_tokenize(corpus)\n",
        "print(Words)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ouNXP8SPv5Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## here '.' is not considered as seperate word except for the last one.\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "d0W9hQaqwhS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1SdiIoyPxckv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}